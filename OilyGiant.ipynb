{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"font-size: 28px; font-weight: bold; color: #000080;\">OilyGiant.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contenido</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del proyecto\n",
    "## Descripcion del codigo\n",
    "## Cargar librerias\n",
    "## Cargar datos\n",
    "## Análisis datos exploratorios\n",
    "## Preparar datos\n",
    "## Construcción y Evaluación del modelo\n",
    "## Calculo de ganancias\n",
    "## Resumen Ejecutivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px;font-weight: bold;\">Descripción del proyecto</span>\n",
    "\n",
    "El proyecto consiste en seleccionar las mejores ubicaciones para abrir 200 nuevos pozos petroleros, utilizando datos de tres regiones. Se emplea regresión lineal para predecir el volumen de reservas, se evalúa el beneficio potencial de cada región considerando el presupuesto y los ingresos esperados, y se calcula el riesgo de pérdidas utilizando bootstrapping. Se elige la región con el mayor beneficio promedio y riesgo de pérdidas inferior al 2.5%. Se deben seguir instrucciones específicas, preparar datos, entrenar modelos, calcular ganancias y riesgos, y justificar la elección de la región óptima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; font-weight: bold;\"> Descripción del código</span>\n",
    "\n",
    "Preparación de datos:\n",
    "Se cargaron y exploraron tres conjuntos de datos (geo_data_0.csv, geo_data_1.csv, geo_data_2.csv) que contienen información sobre características geológicas y volumen de reservas en pozos petroleros.\n",
    "Se verificó la consistencia de los conjuntos de datos y se observaron las distribuciones de las variables.\n",
    "Se confirmó que no hay valores negativos en la columna de volumen de reservas ('product').\n",
    "Se dividió cada conjunto de datos en conjuntos de entrenamiento y validación, escalando las características utilizando StandardScaler.\n",
    "\n",
    "Entrenamiento de modelos:\n",
    "Se entrenaron modelos de regresión lineal para cada región utilizando los conjuntos de entrenamiento y se realizaron predicciones en los conjuntos de validación.\n",
    "Se evaluaron los modelos utilizando métricas como el error cuadrático medio (MSE), la raíz del error cuadrático medio (RMSE) y el coeficiente de determinación (R2).\n",
    "Se observó que los modelos tienen un rendimiento aceptable en la predicción del volumen de reservas. \n",
    "\n",
    "Cálculo de ganancias potenciales:\n",
    "Se estableció un presupuesto y se calculó la cantidad mínima de reservas necesarias para evitar pérdidas.\n",
    "Se compararon las predicciones de volumen de reservas promedio con la cantidad necesaria para cada región.\n",
    "Se identificaron los 200 mejores pozos para cada región y se calculó la ganancia potencial.\n",
    "Se sugirió una región para el desarrollo de pozos petroleros basada en las ganancias potenciales calculadas.\n",
    "\n",
    "Evaluación de riesgos y ganancias:\n",
    "Se utilizó la técnica de bootstrapping para estimar la distribución de ganancias potenciales.\n",
    "Se calcularon el beneficio promedio, el intervalo de confianza del 95% y el riesgo de pérdidas para cada región.\n",
    "Se propuso una región para el desarrollo de pozos petroleros considerando los riesgos y ganancias estimados.\n",
    "Se comparó la elección basada en riesgos y ganancias con la elección basada en las ganancias potenciales solamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; font-weight: bold;\">Cargar Librerias</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de librerias\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; font-weight: bold;\">Cargar datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "try:\n",
    "    region_cero = pd.read_csv('geo_data_0.csv')\n",
    "except:\n",
    "    region_cero = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "\n",
    "try:\n",
    "    region_uno = pd.read_csv('geo_data_1.csv')\n",
    "except:\n",
    "    region_uno = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "\n",
    "try:\n",
    "    region_dos = pd.read_csv('geo_data_2.csv')\n",
    "except:\n",
    "    region_dos = pd.read_csv('/datasets/geo_data_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(region_cero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(region_uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(region_dos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px; font-weight: bold;\">Análisis Exploratorio de Datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información General datasets.\n",
    "print('From the tables above, I can understand that the three dataset are equals.')\n",
    "print('Their shape looks like:')\n",
    "print()\n",
    "print(region_cero.shape)\n",
    "print()\n",
    "print('The 3 datasets have {0}'.format(region_cero.shape[0]), 'rows.')\n",
    "print()\n",
    "print('The 3 datasets have {0}'.format(region_cero.shape[1]), 'columns.')\n",
    "print()\n",
    "print('The 3 datasets has {0}'.format(region_cero.duplicated().sum()), 'duplicates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describir método para conjunto de datos.\n",
    "print('region_cero describe method:')\n",
    "print(region_cero.describe())\n",
    "print()\n",
    "print('region_uno describe method:')\n",
    "print(region_uno.describe())\n",
    "print()\n",
    "print('region_dos describe method:')\n",
    "print(region_dos.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigando columnas en geo_1\n",
    "for column in region_uno:\n",
    "    columnSeriesObj = region_uno[column]\n",
    "    print('Column Name : ', column)\n",
    "    print()\n",
    "    print('Column Contents :')\n",
    "    print(columnSeriesObj.value_counts(dropna=False))\n",
    "    print()\n",
    "    print('The number of unique value is:', columnSeriesObj.nunique())\n",
    "    print()\n",
    "    print('--------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigando columnas en geo_2\n",
    "for column in region_dos:\n",
    "    columnSeriesObj = region_dos[column]\n",
    "    print('Column Name : ', column)\n",
    "    print()\n",
    "    print('Column Contents :')\n",
    "    print(columnSeriesObj.value_counts(dropna=False))\n",
    "    print()\n",
    "    print('The number of unique value is:', columnSeriesObj.nunique())\n",
    "    print()\n",
    "    print('--------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Luego del análisis se puede notar que con respecto al estado inicial, los conjuntos de datos geo_0, geo_1, y geo_2 comparten una estructura común de 100,000 filas y 5 columnas, pero muestran diferencias significativas en las estadísticas descriptivas y distribuciones de valores. Aunque no se encontraron duplicados, la presencia de identificadores duplicados en geo_1 y geo_2 podría requerir una mayor investigación. La variación en la distribución de los valores del objetivo sugiere diferentes fuentes de datos o metodologías de recopilación. Estas diferencias deben considerarse cuidadosamente para evitar sesgos en el análisis y modelado subsiguientes. Es crucial abordar estas discrepancias para garantizar la integridad y precisión de cualquier conclusión derivada de estos conjuntos de datos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px; font-weight: bold;\">Preparación de datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Comprobar si la columna 'producto' contiene valores negativos, se espera un df vacío\n",
    "print(region_cero.query('product < 0'))\n",
    "print(region_uno.query('product < 0'))\n",
    "print(region_dos.query('product < 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Don't need to prepare data. I can move further on model training.\")\n",
    "print(\"Doesn't even make any sense to analyze target balance. Considered that we need to perfom a linear regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors para cada region\n",
    "colors = ['green', 'yellow', 'orange']  \n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
    "\n",
    "for i, region in enumerate([region_cero, region_uno, region_dos]):\n",
    "  # Calculate column index for each region (avoiding modulo)\n",
    "  col = i\n",
    "\n",
    "  # Create histogram with specific color and transparency\n",
    "  axs[col].hist(region['product'], color=colors[i], alpha=0.5)\n",
    "\n",
    "  # Set title for each subplot\n",
    "  axs[col].set_title(f'Region {i+1} Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# **Relaciones entre variables con gráficos de dispersión**\n",
    "# Matriz de dispersión para geo_0\n",
    "sns.pairplot(region_cero, palette=\"Green\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios sobre la matriz de dispersión para geo_0:\n",
    "\n",
    "1. Identificación de relaciones entre variables:\n",
    "La matriz de dispersión muestra las relaciones entre todas las variables numéricas en el conjunto de datos geo_0. Cada punto en la matriz representa la relación entre dos variables específicas. Si los puntos forman una nube densa alrededor de la diagonal, indica una correlación débil o nula entre las variables. Si los puntos se distribuyen en forma de línea diagonal ascendente o descendente, indica una correlación positiva o negativa, respectivamente.\n",
    "\n",
    "2. Análisis de la fuerza de la correlación:\n",
    "La fuerza de la correlación se puede evaluar visualmente observando la densidad de los puntos alrededor de la diagonal. Cuanto más densa sea la nube, más fuerte es la correlación. Además, se puede utilizar una escala de color para representar la fuerza de la correlación, donde los colores más intensos indican una correlación más fuerte.\n",
    "\n",
    "3. Identificación de variables relevantes:\n",
    "Al analizar la matriz de dispersión, se pueden identificar las variables que tienen una correlación más fuerte con la variable objetivo (en este caso, \"product\"). Estas variables pueden ser más relevantes para el modelo de aprendizaje automático que se está desarrollando.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "En la imagen proporcionada, se observan algunas correlaciones interesantes entre las variables:\n",
    "\n",
    "La variable a parece tener una correlación positiva moderada con la variable 0.\n",
    "La variable 0500 parece tener una correlación negativa débil con la variable 50.\n",
    "La variable 100 parece tener una correlación positiva débil con la variable 150.\n",
    "Es importante recordar que la matriz de dispersión solo proporciona una vista visual de las relaciones entre variables. Para una evaluación más precisa de la correlación, se pueden utilizar medidas estadísticas como el coeficiente de correlación de Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaciones entre la variable objetivo ('product') y otras variables numéricas en geo_0\n",
    "for col in region_cero.select_dtypes(include=[np.number]):\n",
    "    if col != 'product':\n",
    "        sns.scatterplot(\n",
    "            x=region_cero[col],\n",
    "            y=region_cero['product'],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.title(f'Relación entre {col} y Producto en region_cero')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Producto')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(region_cero, x=\"product\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Relaciones entre variables con gráficos de dispersión**\n",
    "# Matriz de dispersión para geo_0\n",
    "sns.pairplot(region_uno)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaciones entre la variable objetivo ('product') y otras variables numéricas en geo_1\n",
    "for col in region_uno.select_dtypes(include=[np.number]):\n",
    "    if col != 'product':\n",
    "        sns.scatterplot(\n",
    "            x=region_uno[col],\n",
    "            y=region_uno['product'],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.title(f'Relación entre {col} y Producto en region_uno')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Producto')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(region_uno, x=\"product\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de frecuencias del producto por categorías en geo_1\n",
    "region_uno['product'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribución de Producto por Categoría en region_uno')\n",
    "plt.xlabel('Categoría de Producto')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de dispersión para geo_2\n",
    "sns.pairplot(region_dos)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaciones entre la variable objetivo ('product') y otras variables numéricas en geo_2\n",
    "for col in region_dos.select_dtypes(include=[np.number]):\n",
    "    if col != 'product':\n",
    "        sns.scatterplot(\n",
    "            x=region_dos[col],\n",
    "            y=region_dos['product'],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.title(f'Relación entre {col} y Producto en region_dos')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Producto')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(region_dos, x=\"product\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen - Punto 1**\n",
    "\n",
    "Empezamos importando los tres conjuntos de datos sobre regiones. Los 3 marcos de datos presentan 100 mil filas cada uno, divididas en 5 columnas. Estos tres conjuntos de datos tienen una estructura poco comprensible y no necesitamos entender qué significan las columnas. Lo importante al trabajar con esos datos es entender que tenemos 3 columnas como características, una para el id de los pozos y otra que es nuestro objetivo representa el volumen de producto para cada pozo. Teniendo en cuenta que cada unidad puede generar 4500$, podemos continuar nuestro estudio.\n",
    "\n",
    "Los datos ya están preparados no necesitamos preprocesarlos ya que no presentan duplicados ni NaN en las filas.\n",
    "\n",
    "Tratándose de una variable continua como objetivo está claro que necesitamos un modelo de tipo regresión para tratarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar y probar el modelo para cada región."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los conjuntos de datos geo_0, geo_1 y geo_2 muestran variaciones en las distribuciones de datos, evidenciadas por diferencias en estadísticas descriptivas y la distribución de valores objetivo (product). Aunque no se encontraron valores negativos en la columna product, indicando consistencia en los datos, las características y los objetivos pueden diferir entre regiones. Por lo tanto, para el modelado y análisis subsiguientes, es crucial considerar estas variaciones y adaptar las estrategias según las particularidades de cada región.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separar los datos en un conjunto de entrenamiento y un conjunto de validación en una proporción de 75:25.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_0\n",
    "features_0 = region_cero.drop(['product','id'], axis=1)\n",
    "target_0 = region_cero['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_0\n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear una variable objetivo para geo_1\n",
    "y_true = region_uno['product'].values\n",
    "\n",
    "#Impresion de variable misma y len de variable\n",
    "print('y_true:',y_true)\n",
    "print()\n",
    "print('y_true lenght:',len(y_true)) #Debería devolver la longitud del marco de datos inicial.\n",
    "\n",
    "#Realizo este paso sólo en este marco de datos, porque no puedo estratificar marcos de datos donde valores únicos == len(data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_1\n",
    "train_1, valid_1 = train_test_split(region_uno, stratify=y_true, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_1\n",
    "features_train_1 = train_1.drop(['product','id'], axis=1)\n",
    "target_train_1 = train_1['product']\n",
    "features_valid_1 = valid_1.drop(['product','id'], axis=1)\n",
    "target_valid_1 = valid_1['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_2\n",
    "features_2 = region_dos.drop(['product','id'], axis=1)\n",
    "target_2 =region_dos['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = train_test_split(features_2, target_2, test_size=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asignar escalador -scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escala geo_0 df.\n",
    "features_train_0 = scaler.fit_transform(features_train_0)\n",
    "features_valid_0 = scaler.transform(features_valid_0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar geo_1 df.\n",
    "features_train_1 = scaler.fit_transform(features_train_1)\n",
    "features_valid_1 = scaler.transform(features_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escala geo_2 df.\n",
    "features_train_2 = scaler.fit_transform(features_train_2)\n",
    "features_valid_2 = scaler.transform(features_valid_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los datos de la región 1 no se escalan porque la estratificación basada en el objetivo (y_true) ya está realizada antes de dividir los datos en conjuntos de entrenamiento y validación. La estratificación garantiza que la distribución de los valores objetivo sea la misma en ambos conjuntos. Dado que la estratificación ya equilibra la distribución del objetivo entre los conjuntos de entrenamiento y validación, el escalado adicional puede no ser necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el modelo y hacer predicciones para el conjunto de validación.\n",
    "\n",
    "<span style=\"font-size: 16px; font-weight: bold;\">Construcción del modelo y Evaluación del modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de regresión lineal para geo_0\n",
    "model_0 = LinearRegression()\n",
    "model_0.fit(features_train_0, target_train_0)\n",
    "predictions_valid_0 = model_0.predict(features_valid_0) \n",
    "\n",
    "mse = mean_squared_error(target_valid_0, predictions_valid_0)\n",
    "rmse = mean_squared_error(target_valid_0, predictions_valid_0)**0.5\n",
    "r2 = r2_score(target_valid_0, predictions_valid_0)\n",
    "print('Coefficient:', model_0.coef_)\n",
    "print('Intercept:', model_0.intercept_)\n",
    "print('Linear regression mse (Mean Squared Error):', mse)\n",
    "print('Linear regression rmse (Root-Mean-Square Deviation):', rmse) \n",
    "print('Linear regression r2 score (Coefficient of Determination):', r2)\n",
    "print()\n",
    "print('Average volume of predictions for geo_0 model is:', predictions_valid_0.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(x=target_valid_0, y=predictions_valid_0, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_1 Modelo de regresión lineal.\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(features_train_1, target_train_1) # < entrenar el modelo >\n",
    "predictions_valid_1 = model_1.predict(features_valid_1) \n",
    "\n",
    "mse = mean_squared_error(target_valid_1, predictions_valid_1)\n",
    "rmse = mean_squared_error(target_valid_1, predictions_valid_1)**0.5\n",
    "r2 = r2_score(target_valid_1, predictions_valid_1)\n",
    "print('Coefficient:', model_1.coef_)\n",
    "print('Intercept:', model_1.intercept_)\n",
    "print('Linear regression mse (Mean Squared Error):', mse)\n",
    "print('Linear regression rmse (Root-Mean-Square Deviation):', rmse) \n",
    "print('Linear regression r2 score (Coefficient of Determination):', r2)\n",
    "print()\n",
    "print('Average volume of predictions for geo_1 model is:', predictions_valid_1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(x=target_valid_1, y=predictions_valid_1, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique values in geo_1 target:',region_uno['product'].nunique())\n",
    "print()\n",
    "print('region_uno target normalized count of values:')\n",
    "print(region_uno['product'].value_counts(normalize=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_2 Modelo de regresión lineal.\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(features_train_2, target_train_2) # \n",
    "predictions_valid_2 = model_2.predict(features_valid_2) \n",
    "\n",
    "mse = mean_squared_error(target_valid_2, predictions_valid_2)\n",
    "rmse = mean_squared_error(target_valid_2, predictions_valid_2)**0.5\n",
    "r2 = r2_score(target_valid_2, predictions_valid_2)\n",
    "print('Coefficient:', model_2.coef_)\n",
    "print('Intercept:', model_2.intercept_)\n",
    "print('Linear regression mse (Mean Squared Error):', mse)\n",
    "print('Linear regression rmse (Root-Mean-Square Deviation):', rmse) \n",
    "print('Linear regression r2 score (Coefficient of Determination):', r2)\n",
    "print()\n",
    "print('Average volume of predictions for geo_2 model is:', predictions_valid_2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(x=target_valid_2, y=predictions_valid_2, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar las predicciones y las respuestas correctas para el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving cross validation target values in variables to be able, to compare that to the model results obtained.')\n",
    "print()\n",
    "checking_values_0 = target_valid_0 #Esto se convertirá en el array para comprobar la precisión de nuestro modelo.\n",
    "checking_values_1 = target_valid_1 \n",
    "checking_values_2 = target_valid_2 \n",
    "\n",
    "print('checking_values_0 is an array with', len(checking_values_0),'values.')\n",
    "print('checking_values_1 is an array with', len(checking_values_1),'values.')\n",
    "print('checking_values_2 is an array with', len(checking_values_2),'values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen - Punto 2**\n",
    "\n",
    "Al principio de este paso he dividido los tres dataframes con un ratio de 75:25, definiendo cuales son las características y el objetivo. Obviamente, excluí el índice de ambas categorías, ya que esta columna sólo es útil para identificar el pozo. Solo para el \"Area Geografica 1\" decidi estratificar la division en la variable objetivo. He hecho este paso solo con este marco de datos ya que no tiene sentido hacer lo mismo en las otras dos areas geograficas considerando que estan distribuidas demasiado uniformemente.\n",
    "Escalado de los tres dataframes con la librería StandardScaler.\n",
    "Como dije antes el modelo elegido para el proyecto es uno de regresión lineal.\n",
    "Comencé a construir los modelos y a calcular las distintas métricas para cada uno de ellos:\n",
    "Obtuve para el \"Área Geográfica 0\" un rmse de 37.48, un r2_score de 0.28 y un volumen medio de mis predicciones de 92.51. Trazando esta área geográfica podemos ver fácilmente la correlación lineal y la distribución de los puntos en el diagrama de dispersión.\n",
    "Para el \"Área geográfica 1\" se ha obtenido un rmse de 0,88, un r2_score de 0,99 y un volumen medio de mis predicciones de 68,82. Trazando esta área geográfica vemos una correlación positiva más fuerte y los puntos están distribuidos casi por igual en los mismos lugares, podemos identificar 12 grupos de puntos en el diagrama de dispersión, esto respecto a los valores únicos encontrados en el objetivo (12).\n",
    "He obtenido para el \"Área geográfica 2\" un rmse de 39,98, un r2_score de 0,19 y el volumen medio de mis predicciones es de 95,13. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px; font-weight: bold;\">Calculo de ganancias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacene todos los valores clave para los cálculos en variables separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Almacenando variables útiles.\n",
    "BUDGET=100000000 #En USD.\n",
    "BARREL_REVENUE = 4.5 #Dolares.\n",
    "RESERVES = 1000\n",
    "UNIT_PRODUCT_REVENUE = 4500 #Dolares\n",
    "MILLION = 1000000\n",
    "COUNT = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular el volumen de reservas suficiente para desarrollar un nuevo pozo sin pérdidas. Compara el valor obtenido con el volumen medio de reservas de cada región.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Barriles necesarios para alcanzar nuestro presupuesto.\n",
    "BARREL_NEEDED = BUDGET / BARREL_REVENUE \n",
    "print('To reach 100 Million dollars necessaries for 200 oil wells are needed: {:.2f}'.format(BARREL_NEEDED/MILLION), 'Million barrels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unidades de producto necesarias para alcanzar nuestro presupuesto en la región.\n",
    "UNITS_REGION = BUDGET / UNIT_PRODUCT_REVENUE\n",
    "print('To reach our Budget we need {:.2f}'.format(UNITS_REGION),'product units in the entire region.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unidades de producto necesarias para alcanzar nuestro presupuesto en un solo pozo.\n",
    "UNITS_WELL = UNITS_REGION / 200\n",
    "print('To reach our Budget we need {:.2f}'.format(UNITS_WELL),'product units in a single well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparar el resultado con las medias.\n",
    "\n",
    "result_0 = predictions_valid_0.mean() - UNITS_WELL\n",
    "result_1 = predictions_valid_1.mean() - UNITS_WELL\n",
    "result_2 = predictions_valid_2.mean() - UNITS_WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The comparation between average volume in wells and units needed per wells in geo_0 is: {:.2f}'.format(result_0))\n",
    "print('The comparation between average volume in wells and units needed per wells in geo_1 is: {:.2f}'.format(result_1))\n",
    "print('The comparation between average volume in wells and units needed per wells in geo_2 is: {:.2f}'.format(result_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen - Punto 3**\n",
    "\n",
    "Almacenados todos los valores necesarios para concluir el análisis y calcular los ingresos.\n",
    "Las constantes derivadas son\n",
    "el presupuesto = 100 millones de dólares\n",
    "el precio de un barril de petróleo = 4,5 dólares\n",
    "las reservas = 1000 (cada unidad contiene 1000 barriles)\n",
    "los ingresos por cada unidad de producto 4500\n",
    "constante con un valor de 1 Millón sólo para evitar repetir números y dejar que el código sea más legible\n",
    "He calculado el número de barriles necesarios para alcanzar los 100 millones (nuestro presupuesto), resultando 22,22 millones de barriles de petróleo. Esto hace un total de 22222.22 unidades de producto necesarias y 111.11 para cada pozo.\n",
    "Se comparan las unidades de producto necesarias para cada pozo con el volumen medio: geo_0 = -18.84 geo_1 = -42.29 geo_2 = -16.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escribir una función para calcular el beneficio de un conjunto de pozos petrolíferos seleccionados y las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir una función para obtener los 200 mejores pozos de cada región.\n",
    "def profit(geo, predictions):\n",
    "    predictions_sorted = pd.Series(predictions, geo.index).sort_values(ascending=False)\n",
    "    top_target = geo.loc[predictions_sorted.index][:COUNT]\n",
    "    profit = (((top_target.sum() * UNIT_PRODUCT_REVENUE) - BUDGET) / MILLION)\n",
    "    return profit\n",
    "\n",
    "#Obtener las predicciones de los 200 mejores pozos para cada región, guardando los valores obtenidos en diferentes variables.\n",
    "profit_geo_0 = profit(target_valid_0, predictions_valid_0)\n",
    "profit_geo_1 = profit(target_valid_1, predictions_valid_1)\n",
    "profit_geo_2 = profit(target_valid_2, predictions_valid_2)\n",
    "profit_df = (pd.DataFrame([profit_geo_0, profit_geo_1, profit_geo_2], columns=['Profit']))\n",
    "profit_df = profit_df.reset_index()\n",
    "profit_df.columns=['Geographic Area (geo)', 'Profit (USD Millions)']\n",
    "profit_df = profit_df.set_index('Geographic Area (geo)')\n",
    "display(profit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen - Punto 4**\n",
    "\n",
    "Definida una función para calcular el beneficio, esta función toma antes los 200 mejores pozos y devuelve el beneficio en Millones. Esta función necesita ser pasada a la técnica de bootstrapping para obtener por cada 500 muestras los mejores 200 pozos. Y devolver el cuantil superior e inferior.\n",
    "He trazado un gráfico mostrando el beneficio resultante de los 200 mejores pozos para las 3 áreas geográficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: px; font-weight: bold;\">Bootstrapping y cálculo estadístico</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir función para ejecutar bootstrapping para encontrar intervalos de confianza.\n",
    "def bootstrap(target, predictions):\n",
    "    state = np.random.RandomState(12345)\n",
    "    # Almacenar los valores de los cuantiles del 95% en la variable valores. \n",
    "    #Como nos interesa el cuantil del 95%, buscamos valores entre el 2,5% y el 97,5%.\n",
    "    profit_list = []\n",
    "    target_valid = target.reset_index(drop=True)\n",
    "    for i in range(1000):\n",
    "        target_subsample = target_valid.sample(n=500, replace=True, random_state=state)\n",
    "        predictions_subsample = predictions[target_subsample.index]\n",
    "        profit_list.append(profit(target_subsample, predictions_subsample)) \n",
    "    profit_list = pd.Series(profit_list)\n",
    "    lower = profit_list.quantile(0.025)\n",
    "    upper = profit_list.quantile(0.975)\n",
    "    risk = len(profit_list[profit_list < 0]) / len(profit_list) * 100\n",
    "    print('The distribution of product volume is included in a range among {:.2f}'.format(lower),'and {:.2f}'.format(upper), 'units.')\n",
    "    print('The risk percentage is:', risk,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular la gama de volúmenes de productos geo_0 y los posibles riesgos.\n",
    "print('Confidence interval for geo_0.')\n",
    "bootstrap(target_valid_0, predictions_valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular el rango de volumen de producto geo_0 y los posibles riesgos\n",
    "print('Confidence interval for geo_1.')\n",
    "bootstrap(target_valid_1, predictions_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo de la gama de volúmenes del producto geo_0 y posibles riesgos.\n",
    "print('Confidence interval for geo_2.')\n",
    "bootstrap(target_valid_2, predictions_valid_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mantener sólo las regiones con un riesgo de pérdidas inferior al 2,5%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La zona más conveniente para invertir es geo_1 porque tiene un riesgo negativo.**\n",
    "Esto significa que en esta zona estamos casi seguros de no tener pérdidas. El intervalo de confianza de la región nos lleva a pensar que es la zona mucho más conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen - Punto 5**\n",
    "\n",
    "Se crean dos listas para almacenar los valores inferiores y superiores de nuestros intervalos de confianza, esto para permitirnos ser capaces de definir el riesgo de la región. Definí una función para realizar bootstrappings en las distintas regiones. Esta función bootstrap calcular el intervalo de confianza para el 95% de los valores cuantílicos. Manteniendo fuera el 2,5% de la parte inferior y el 2,5% de la parte superior de nuestra distribución. La muestra utilizada en nuestra técnica bootstrap está compuesta por 500 pozos y se repite el proceso durante 1000 veces.\n",
    "Para calcular los riesgos, voy a tomar la proporción de valores de beneficios negativos sobre el total de valores de beneficios y obteniendo sus porcentajes.\n",
    "Intervalos de confianza :\n",
    "geo_0 entre -0,61 y 9,81.\n",
    "geo_1 entre +0,71 y 9,51.\n",
    "geo_2 entre -2,27 y 8,53.\n",
    "Riesgos:\n",
    "geo_0 igual a + 4,70%\n",
    "geo_1 igual a + 1,40%.\n",
    "geo_2 igual a +12, Después de estos cálculos resultó que geo_1 es la zona más conveniente para construir un nuevo pozo de petróleo ya que no tenemos en absoluto riesgos de pérdidas y nuestro intervalo de confianza está entre números positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16px; font-weight: bold;\">Resumen Ejecutivo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:**\n",
    "\n",
    "Analizar datos geológicos para predecir el volumen de producción en pozos petroleros y estimar las ganancias potenciales en diferentes áreas geográficas.\n",
    "\n",
    "**Metodología:**\n",
    "\n",
    "Se importaron y analizaron tres conjuntos de datos geológicos.\n",
    "Se dividieron los datos en entrenamiento y validación.\n",
    "Se entrenaron modelos de regresión lineal para cada área geográfica.\n",
    "Se calcularon las métricas de evaluación del modelo (MSE, RMSE, R-squared).\n",
    "Se visualizó la relación entre las variables reales y predichas.\n",
    "Se definió una función para calcular el beneficio.\n",
    "Se calculó el beneficio para los 200 pozos principales en cada región.\n",
    "Se realizó un análisis de bootstrapping para estimar el intervalo de confianza de la producción predicha.\n",
    "Se calculó el riesgo de obtener una producción menor a la estimada.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "El \"Área Geográfica 1\" presenta la mejor correlación entre las variables y el menor riesgo de obtener una producción menor a la estimada.\n",
    "El intervalo de confianza para el \"Área Geográfica 1\" se encuentra entre valores positivos, lo que indica un alto potencial de ganancias.\n",
    "Se recomienda invertir en el \"Área Geográfica 1\" para la construcción de un nuevo pozo petrolero.\n",
    "\n",
    "**Conclusiones:**\n",
    "\n",
    "El análisis de datos geológicos permite identificar áreas con alto potencial de producción de petróleo.\n",
    "El uso de modelos de regresión lineal y técnicas de bootstrapping ayuda a estimar las ganancias potenciales y el riesgo asociado a la inversión.\n",
    "El \"Área Geográfica 1\" es la zona más favorable para la inversión en la construcción de un nuevo pozo petrolero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 317,
    "start_time": "2024-05-24T17:12:12.986Z"
   },
   {
    "duration": 22,
    "start_time": "2024-05-24T17:12:18.191Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
